bf16_flash_attention_fwd:
    op: flash_attention
    args: --op flash_attention --only triton_tutorial_flash_v2 --num-inputs 1 --input-id 6 --metrics tflops --cudagraph --simple-output --precision bf16 --d-head 128
