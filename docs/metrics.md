# TritonBench Metrics

TritonBench supports two types of metrics: built-in and user-defined.
All metrics are specified with `--metrics <METRIC_NAMES>` option, where `<METRIC_NAMES>` are built-in or user-defined metric names separated by comma.

## Built-in metrics

TritonBench supports a rich set of built-in metrics.

| Metric Name     | Definition                                                                                        |
|-----------------|---------------------------------------------------------------------------------------------------|
| `latency`       | The latency given by `triton.testing.do_bench`.                                                   |
| `kineto_trace`  | Chrome Trace generated by Kineto.                                                                 |
| `walltime`      | CPU-side wall latency, including CPU kernel launch time.                                          |
| `cuda_time`     | Sum of all GPU-side kernels time of an operator backend, measured by Kineto and PyTorch Profiler. |
| `ncu_rep`       | (NVIDIA-only) Generate the NVIDIA NSight Compute Replay file.                                     |
| `speedup`       | (Requires baseline backend) Latency speedup comparing to the baseline backend.                    |
| `accuracy`      | (Requires baseline backend) Numeric accuracy comapring to the baseline backend.                   |
| `compile_time`  | (Triton-only) Triton compile time.                                                                |
| `compile_trace` | (Triton-only) Kineto profiling of Triton compile.                                                 |


For most of the built-in metrics (e.g., `latency`,`kineto_trace`,`cuda_time`), user can use the `--cudagraph` option to improve reduce the CPU-side launch overhead.


## User-defined metrics

Additionally, users can define customized metrics or override  in `operator.py` using the `@register_metric` decorator.

Here are some examples:

- [tflops](https://github.com/pytorch-labs/tritonbench/blob/70264720fbfbb13020f63d4f8ddf9389abd54841/tritonbench/operators/grouped_gemm/operator.py#L47)
- [occupacy](https://github.com/pytorch-labs/tritonbench/blob/70264720fbfbb13020f63d4f8ddf9389abd54841/tritonbench/operators/jagged_sum/operator.py#L251)
- [gbps](https://github.com/pytorch-labs/tritonbench/blob/70264720fbfbb13020f63d4f8ddf9389abd54841/tritonbench/operators/softmax/operator.py#L125)
